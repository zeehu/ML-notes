熵（entropy）表示随机变量不确定性的度量；
	熵越大，随机变量的不确定性就越大

信息增益（information gain）表示得知特征X的信息而使得类Y的信息的不确定性减少的程度